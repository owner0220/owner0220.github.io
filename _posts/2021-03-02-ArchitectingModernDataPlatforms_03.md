---
title: Architecting Modern Data Platforms 03
date: 2021-03-03 14:22:00
categories:
 - HADOOP
tag:
 - hadoop
---

### 3장 연산과 스토리지

컴퓨터 아키텍처와 리눅스 운영체제 세부 내용 중 중요한 부분을 다뤄보고, 각 서버의 용량에 대해 알아본 다음, 마지막으로 이런 각 유형의 서버가 어떻게 표준 클러스터로 합쳐질 수 있는지 살펴본다.

<!-- more -->

#### 하둡 이해를 위한 컴퓨터 아키텍쳐

##### 보급형 서버

하둡은 2개의 프로세서를 가진 시스템(2소켓 시스템)으로 구성돼 있다. 2개의 CPU는 각각 3개의 코어를 가지고 있고 인터프로세서 링크로 연결되어 있다. 메모리는 캐시메모리를 사용하며 L1 코어,L2,L3 (숫자가 작을 수록 빠르고 용량이 작다, CPU와 밀접)

##### 서버 CPU와 RAM

- x86 아키텍처의 역할
  - CPU 종류 : 32-bit (x86), 64-bit (x86-64, IA64 and AMD64)
  - x86 이 CPU 90% 이상 점유 현황 (인텔 70%, AMD 30%)
- 하둡 스레드와 코어
  - 하이퍼스레딩
    - SMT(Simultaneous Multi-Threading) - 동시 멀티스레징
      - 단일 코어 하드웨어 효율을 높이기 위함
      - 스레딩간 CPU 캐시 공유
      - 워크로드 처리 효율을 높이는데 큰 역할 (I/O 대기 있다는 전제하)
  - 대칭형 멀티프로세싱
    - SMP(Symmetric Multi Processing) - 대칭형 멀티프로세싱
      - 다수의 코어로 하나의 프로세서 사용 혹은 다수 프로세서 사용

##### 불균일 메모리 접근

- NUMA가 빅데이터에서 왜 중요한가?
  - Non-Uniform Memory Access - 불균일 메모리 접근
    - 로컬 메모리와 원격 메모리 차이
  - 성능에 지대한 차이를 가져올 수 있다.

##### CPU 사양

- 고성능 싱글 스레드에 의존하지 않고 코어 수를 최대화하는 것이 좋다.

##### RAM

- 디스크 사용을 줄이고 메모리에서 실행되게 해야 한다.

#### 엔터프라이즈에 적합한 보급형 스토리지

데이터 크기 (테라바이트에서 페타바이트로), 글로벌 데이터 레이크, 데이터 허브, 데이터 스토어, 테라바이트 데이터를 위한 대역폭

- SAN(Storage Area Network), NAS(Network Attatched Storage) 중심의 기존 데이터 스토리지 설계
  - SAN 기반 하둡은 주로 공개형 클라우드와 관련, 30노드 이상 규모의 클러스터 지원은 드물다. (비용적인 측면에서 자체 장비 기반으로 구성하기 비경제적이기 때문)

##### 연산 및 스토리지의 모듈성

하둡은 연산 및 스토리지가 모듈화된 서버에서도 실행 되도록 발전했다. 하지만 모듈화 하려면 스토리지 네트워크 인프라스트럭처 구축 및 운영에 수백만 달러를 투자해야 한다. 그리고 해당 방식은 공개형 클라우드 같은 초거대규모 환경에서 비용 대비 효과를 얻을 수 있다. 최소한 연산 및 스토리지가 함께 있어야 하며, 이렇게 연산 및 스토리지를 동일 장소에 구성하는 것을 일컬어 코로케이션 이라고 한다.

##### 모든 것이 자바

- HDFS - 자바
- 아파치 카프카, 아파치 쿠두 -  C/C++ 또는 스칼라

##### 복제 또는 이레이저 코딩

알고리즘 적으로 복제를 해결한 것이 이레이저 코딩

##### 대안

보급현 하드웨어에서 수평 확장 가능한 스토리지 엔터프라이즈 환경

- 오브젝트 스토리지

#### 하둡과 리눅스 스토리지 스택

HDFS 및 관련 스토리지 프레임워크가 리눅스 스토리지 서브시스템 및 그 하부 하드웨어와 어떻게 상호작용하는지 중점을 둔다.

##### 사용자 공간

- 비용적인 측면도 무시할 순 없지만 퍼포먼스 적인 측면에서 분리 운영을 권고
  - 별도 노드에서 분리 운영 시 순차 접근으로 얻을 수 있는 처리량 증가 장점을 무시 못함.
- 디스크 구성 시 별도 레이드 구성을 하여야 한다. (ext4 나 XFS 권고)
- 리눅스 모든 시스템 호출은 가상 파일시스템(VFS, Virtual FileSystem)을 거치게 추상화 되어 있다.
  - 하둡 워커 노드 HDFS 데이터노드 같은 사용자 공간 데몬은
    - 클라이언트 읽기 요청을 받으면 리눅스 스토리지 서브시스템에서 블록을 읽어서 TCP/IP를 통해 클라이언트에 전송한다.
    - 클라이언트 쓰기 요청을 받을 때도 마찬가지로 TCP/IP를 통해 클라이언트로부터 블록을 받는다.

##### 주요 시스템 호출

사용자 애플리케이션이 스토리지와 상호작용하는 기본 수단은 시스템 호출

##### 리눅스 페이지 캐시

##### 숏서킷 읽기와 제로카피 읽기

##### 파일시스템

#### 이레이저 코딩과 복제

##### 생각해볼 거리

- 네트워크 성능
- 쓰기 성능
  - 자바 코더
  - ISA-L 코더
- 지역성 최적화
- 읽기 성능

##### 권장 가이드

#### 로우레벨 스토리지

##### 스토리지 컨트롤러

- RAID란?
- 컨트롤러 캐시
- 가이드라인

##### 디스크 계층

- SAS, NL-SAS, SATA(혹은 SSD) 중 어떤 선택?
- 디스크 크기
- 디스크 캐시

#### 서버 폼 팩터

- 랙 마운트 폼 팩터 평가
  - CPU 밀도
  - 메모리 밀도
  - 스토리지 밀도
  - 스토리지 I/O 밀도
  - 네트워크 I/O 밀도
  - 소프트웨어 라이선스 효율성

##### 폼 팩터 비교

##### 가이드

#### 워크로드 프로파일

#### 클러스터 구성과 노드 종류

##### 마스터 노드

##### 워커 노드

##### 유틸리티 노드

##### 엣지 노드

##### 소형 클러스터 구성

##### 중형 클러스터 구성

##### 대형 클러스터 구성

#### 정리