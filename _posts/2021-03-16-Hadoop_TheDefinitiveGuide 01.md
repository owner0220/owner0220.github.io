---
title: Hadoop | The Definitive Guide 01
date: 2021-03-16 18:45:00
categories:
 - PRODUCT
tag:
 - hadoop
---

# 1장 하둡 기초

## Part 1. 하둡과의 만남

우리에게 필요한 것은 커다란 한 대의 컴퓨터가 아니라 매우 많은 컴퓨터로 이뤄진 새로운 시스템이다. - 그레이스 호퍼(Grace Hopper)

분산 시스템의 등장으로 우리에게 필요한 것은 좋은 한 대의 컴퓨터가 아니라 평균적인 매우 많은 컴퓨터 저비용 고효율을 따라간 어떻게 보면 당연한 이치

<!-- more -->

#### 1.1 데이터!

제타바이트=1000 엑사바이트=100만 페타바이트=10억 테라바이트

데이터가 많다.

#### 1.2 데이터 저장소와 분석

예전에는 읽는 속도에 비해 저장되는 데이터가 작아서 문제가 되지 않았지만 지금은 워낙 큰 데이터를 저장하기 때문에 읽기도 느리지만 쓰는건 더 느리다. 하지만 일을 나눠서 병렬로 처리하면 큰 데이터도 빠르게 처리할 수 있다.

하지만 나눠서 저장하는 것은 문제 없지만 각 저장소에 저장된 데이터를 읽어들여서 하나로 종합할 때 정합성이 문제가 된다.

하둡은 맵리듀스로 디스크에서 데이터를 읽고 쓰는 문제를 키-값 쌍의 계산으로 변환한 추상화된 프로그래밍 모델을 제공한다. 여기서 핵심은 계산이 **맵**과 **리듀스**로 분리 되어 있고, 그 둘 사이를 혼합해 주는 인터페이스가 있다는 점이다.

#### 1.3 전체 데이터에 질의하기

맵리듀스, 한 번의 쿼리로 전체나 상당한 규모의 데이터셋을 처리하는 것

#### 1.4 일괄 처리를 넘어서

맵리듀스 강점은 기본적으로 일괄 처리 시스템이라는 것이다. 이는 질의를 실행한 후 수 초 이내에 결과를 받는 것은 불가능하여 대화형 분석에는 적합하지 않다는 것이다.

하둡은 이제 하둡 에코 시스템을 포함한 용어로 쓰인다. 하둡 에코시스템은 분산 컴퓨팅과 대규모 데이터 처리를 위한 기반 시설이다. 

- HBase
  - HDFS를 기본 저장소로 하는 키-값 저장소다.
  - 온라인 접근을 지원하는 첫 번째 구성요소
  - 개별 행에 대한 온라인 읽기/쓰기
  - 산적한 데이터를 읽고 쓰는 일괄 처리 지원
- YARN(Yet Another Resource Negotiator)
  - 클러스터 자원 관리 시스템
  - 맵리듀스 뿐만 아니라 어떤 분산 프로그램도 하둡 클러스터에 저장된 데이터를 처리할 수 있게 해준다.

##### 하둡 기반 다양한 처리 패턴

- 대화형 SQL

  - 맵리듀스 대신 장기 실행 전용 데몬(임팔라) 엔진 사용

  - 컨테이너를 재사용하는 (테즈 기반의 하이브) 분산 쿼리 엔진 사용

    대용량 데이터셋에 대한 확장성이 있으면서 하둡 기반의 SQL 쿼리를 실행할 때 빠른 응답 속도를 갖는다.

- 반복 처리

  - 머신러닝과 같은 다수의 알고리즘은 근본적으로 반복 연산
    - 메모리에 임시 작업 데이터셋을 보존하여 디스크에서 읽는 수고를 줄임
    - 맵리듀스는 안되지만 스파크를 사용하면 데이터셋을 탐색하는 방식의 작업을 허용한다.

- 스트림 처리

  - 스톰 (Storm)
  - 스파크 스트리밍(Spark Streaming)
  - 삼자(Samza)

  실시간 실행되고 경계가 없는 스트림 데이터를 분산 계산하여 그 결과를 하둡 저장소나 외부 시스템에 보낼 수 있다.

- 검색

  - 솔라(Solr)
    - 문서를 색인하여 HDFS에 저장하고 HDFS에 저장된 색인을 기반으로 검색 쿼리를 제공한다.

#### 1.5 다른 시스템과의 비교

##### 1.5.1 관계형 데이터베이스 관리 시스템

여러 개의 디스크를 가진 데이터베이스를 이용해 대규모 분석을 할 수 없는 이유는

- 디스크 드라이브의 하드웨어적 문제
  - 탐색은 데이터를 읽거나 쓸 때 디스크의 헤더를 디스크 특정 위치로 이동시키는 조작
  - 전송 속도는 디스크의 대역폭과 관련

위의 이유로

**맵리듀스**

- 대규모 일괄 처리에 적합

- 한번 쓰고 여러번 읽는 애플리케이션에 적합

**RDBMS**

- 작은 양의 데이터를 빠른 시간에 추출, 변경 위해 데이터셋 색인 (특정 쿼리와 데이터 변경에 적합)

- 지속적으로 변경되는 데이터셋에 적합



**하둡 Vs RDBMS**

- 데이터 종류
  - 정형 데이터
  - 반정형 데이터
  - 비정형 데이터

  하둡은 **처리 시점에 데이터를 해석**(schema-on-read) 하도록 설계되어 있기 때문에 미리 스키마에 대한 정의 없이 저장이 용이하다. 

- 데이터 처리 속도

  하둡은 데이터 크기에 반비례, 클러스터 크기에 비례. 하지만 일반적으로 관계형 데이터베이스 SQL 쿼리는 그렇지 못하다.

##### 1.5.2 그리드 컴퓨팅

네트워크 클러스터는 SAN으로 공유 파일시스템의 대용량 데이터에 접근 할 때 네트워크 대역폭 때문에 병목 현상이 생기고 계산 노드가 놀게 되는 문제가 발생한다. 이에 반해 하둡은 가능하면 계산 노드에 데이터를 함께 배치한다. (**데이터 지역성** Data locality)

**MPI** (**M**essage **P**assing **I**nterface)는 개발자에게 큰 제어권을 주지만, 저수준 C 루틴과 소켓과 같은 구성요소를 통해 데이터 흐름의 메커니즘을 명확하게 다룰 것을 요구한다. 하지만 하둡은 최상위 수준에서 맵리듀스의 키-값과 같은 데이터 모델의 관점에서만 생각하면 된다.

**맵리듀스**는 태스크 간의 상호 의존성이 없는 **비공유** 아키텍처

##### 1.5.3 자발적 컴퓨팅

**SETI**(Search for Extra-Terrestrial Intelligence)는 전파망원경의 데이터를 분석하여 외계의 지적 생명체에 대한 신호를 얻기 위해 자원봉사자들의 컴퓨터가 쉬고 있을 때 CPU의 연산력을 사용한다.

맵리듀스는  높은 네트워크 대역폭의 단일 데이터 센터에 신뢰성 높은 전용 하드웨어에서 수 분 또는 수 시간 내에 잡을 실행 할 수 있도록 설계 되었다.

이와 달리 SETI는 연결 속도가 가변적이고 데이터 지역성이 없는 신뢰할 수 없는 머신에서 오랜 시간이 걸리는 계산을 실행한다.(작업의 신뢰성을 위해 각 작업 단위는 다른 세대의 컴퓨터에 보내지고, 적어도 두 개의 결과가 같아야 그 결과를 인정 받는다.)

#### 1.6 아파치 하둡의 간략한 역사

**Apache Lucene - 더그 커팅**

- 2002년 Apache Nutch
  - 2003년 GFS(Google File System)
  - 2004년 NDFS(Nutch Distributed FileSystem)
  - 2004년 맵리듀스